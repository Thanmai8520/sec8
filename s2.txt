
The purpose of this dashboard is to monitor and visualize the performance and reliability of our BBKYC data processing workflow.
It helps us understand how effectively our Lambda functions are processing data, publishing to downstream systems, and creating Salesforce cases.â€

â¸»

ğŸ§© 2. Give a Brief Architecture Context

â€œOur workflow starts from S3 and EventBridge triggers, and then several Lambda functions handle event publishing, Salesforce case creation, and auditing.
Each Lambda function pushes success/failure metrics to CloudWatch, and those metrics are aggregated here in the dashboard.â€

(If needed, show the architecture diagram you shared earlier to link where each metric comes from.)

â¸»

ğŸ“Š 3. Explain Each Metric Tile Clearly

ğŸŸ¢ S3RecordsProcessed (6)

â€œThis shows the number of records successfully read from the S3 bucket by the Glue job and processed downstream.
It helps ensure the data ingestion layer is functioning.â€

â¸»

ğŸŸ¢ TTPublishSuccess (25)

â€œThis represents the successful transmissions from the Lambda (bbkyc-tt-event-producer) to the TMS system via the Kinesis stream.
It indicates that events are being published and consumed correctly.â€

â¸»

ğŸ”´ TTPublishFailure (â€“)

â€œWe havenâ€™t seen any publish failures in this period, which means no event drop occurred.
If this value rises, it could indicate a downstream service issue or timeout.â€

â¸»

ğŸŸ¢ SFCaseCreationSuccess (37)

â€œThis metric is from the Salesforce case creation Lambda (bbkyc-sf-case-creator).
It tracks the number of cases successfully created in Salesforce after the TMS token validation and event processing.â€

â¸»

âš« SFCaseCreationFailure (0)

â€œCurrently, there are no failures reported in Salesforce case creation.
This shows that our integration is stable and tokens are being refreshed properly.â€

â¸»

ğŸ•’ 4. Time Range Controls

â€œThe dashboard allows switching between different time frames â€” like 1 hour, 3 hours, 1 day, etc.
This helps us perform both real-time and historical trend analysis.â€

â¸»

ğŸ“ˆ 5. Insights / Observations

â€œFrom the past dayâ€™s metrics:

	â€¢	All Salesforce case creations have succeeded.
	â€¢	25 TMS events were successfully published.
	â€¢	No TTPublish or CaseCreation failures, indicating system stability.
	â€¢	S3 processing is consistent, showing 6 records processed.â€

â¸»

âš™ï¸ 6. Next Steps / Recommendations

	â€¢	Add alarms for failure metrics (e.g., SFCaseCreationFailure > 0).
	â€¢	Automate metric reporting into Slack or email.
	â€¢	Include latency and processing duration metrics to monitor performance efficiency.

â¸»

ğŸ—£ï¸ 7. Wrap Up

â€œIn summary, this CloudWatch dashboard gives us end-to-end visibility into our BBKYC pipeline health â€” from data ingestion in S3 to case creation in Salesforce.
It helps us ensure timely detection of issues and smooth data flow across multiple AWS services.â€


git fetch origin
git checkout feature/custom-cloudwatch-metrics
git pull origin feature/custom-cloudwatch-metrics
git merge --no-commit --no-ff origin/base-setup

I checked the DynamoDB table â€” the events are getting logged correctly.
I can see multiple records with status = PROCESSED, while a few show status = FAILED with the reason â€œAPI call failedâ€¦â€.
So the Lambdas are processing events, and their statuses are updating properly in the DB.

BBKYC-AUDIT-DATA-PROCESSOR/
â”‚
â”œâ”€â”€ event/
â”‚   â””â”€â”€ input.json
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚
â”‚       â”œâ”€â”€ common/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ common_aws.py
â”‚       â”‚   â””â”€â”€ common.py
â”‚       â”‚
â”‚       â”œâ”€â”€ helper/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ audit.py
â”‚       â”‚   â””â”€â”€ statusHistory.py
â”‚       â”‚
â”‚       â”œâ”€â”€ app.py
â”‚       â””â”€â”€ test/
â”‚           â””â”€â”€ test_app.py
â”‚
â”œâ”€â”€ metadata.yaml
â”œâ”€â”€ product.template.yaml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ sample-data2.json
â””â”€â”€ setup.sh

Producer lambda changes for parallelization
Shard Distribution Issue
	â€¢	All events going to single shard (Shard 16) despite multiple shards available (7, 11, 14, 16, 17)
	â€¢	Parallelization not taking effect due to poor distribution
	â€¢	Root cause: partition key implementation in producer lambda needs modification
Required Code Changes
	â€¢	Update partition key in BDP Consumer Lambda (rename from â€œBDP Producerâ€)
	â—¦	Change to: existing string + transaction ID
	â—¦	Generates new partition key for each transaction
	â€¢	Convert remaining printf statements to logger statements
	â—¦	Code review needed but will be handled separately by Ria
	â€¢	Focus only on partition key changes for now
Deployment Process
	â€¢	Make changes in feature branch without merging initially
	â€¢	Package and deploy lambda to sandbox environment first
	â€¢	Test functionality before proceeding with merge
	â€¢	After deployment confirmed working:
	1	Take pull from base setup branch
	2	Resolve any merge conflicts carefully
	3	Raise PR/MR request
Technical Issues
	â€¢	Screen glitching problems affecting both participants
	â—¦	Similar issue experienced for 6-7 days previously
	â—¦	Suspected hardware/heat issues with Mac machines
	â€¢	Display problems may impact development timeline
Next Steps
	â€¢	Immediate: Make partition key changes and deploy to sandbox
	â€¢	Priority: Enable 50,000 record processing capability
	â€¢	Later: Complete branch merging and conflict resolution after initial deployment confirmed working

Partitionkey unique key with transaction id force it to publish to new shard so data will distribute all along


#
Metric Name
What It Tracks
Where Itâ€™s Published (Lambda)
Purpose
1
S3 Record Count
Number of files/records successfully read from the S3 bucket (bbkyc-tc-bdp-bucket or similar)
Lambda: bbkyc-tc-event-producer (after reading from S3)
Helps verify that input data ingestion is working and how many records are processed per trigger.
2
TT Event Publish Success
Count of successful â€œTT eventsâ€ pushed into Kinesis Data Stream (bbkyc-tt-event-stream)
Lambda: bbkyc-tt-event-producer
Confirms that event generation and publishing to the stream are functioning as expected.
3
TT Event Publish Failure
Count of failures when publishing TT events to Kinesis
Same Lambda: bbkyc-tt-event-producer (inside catch/error block)
Helps identify reliability issues or connectivity errors with the event stream.
4
Salesforce Case Creation Success
Number of successfully created Salesforce cases (via REST API call)
Lambda: bbkyc-tf-case-creator
Tracks successful case creation in Salesforce â€” validates downstream integration.
5
Salesforce Case Creation Failure
Number of failed Salesforce case creations
Lambda: bbkyc-tf-case-creator (error handling block)
Detects external API errors, token issues, or invalid data causing failures.



Monitoring dashboard setup for AWS Lambda metrics
AWS CloudWatch Dashboard Setup
	â€¢	Lambda trigger process explanation
	â—¦	Upload JSON file to S3 â†’ Lambda triggers â†’ Metrics generated â†’ Pushed to internal metric store
	â—¦	Monitoring dashboard reads metric points independently of alarm triggers
	â—¦	Statistical analysis options: average, summation, P99 percentile calculations
	â€¢	Widget configuration walkthrough
	â—¦	Add multiple metrics to same widget via plus button â†’ Browse â†’ AWS Lambda namespace
	â—¦	Search by function name or resource name
	â—¦	Graph matrices tab shows multiple values
	â—¦	Rename widget labels for clarity (AWS generates random unique names)
Error Handling Strategy
	â€¢	Two approaches for Lambda error tracking
	1	Code fails â†’ Lambda fails â†’ Error propagates to top (captured by AWS Lambda error matrix)
	2	Handle errors in code â†’ Lambda never fails â†’ Generate custom error matrices from code
	â€¢	Review existing producer Lambda error handling
	â—¦	Determine if failures are captured at Lambda error matrix level
	â—¦	Decide between infrastructure-level vs application-level error tracking
	â€¢	Widget naming: Use descriptive titles like â€œTT Publish failureâ€ instead of AWS defaults
Dashboard Enhancement Requirements
	â€¢	Add text sections describing what matrices mean
	â—¦	Business users need context without technical knowledge
	â—¦	Make dashboard self-explanatory for non-developers
	â€¢	Uncheck sparkline option to reduce visual clutter (Edit â†’ Options tab)
	â€¢	Current data shows only single record processing - need more data for proper testing
Next Steps
	â€¢	Ria: Resolve WiFi issues, complete scenario generation
	â€¢	Review and update error handling in producer Lambda
	â€¢	Beautify dashboard with descriptive text sections
	â€¢	Follow up after implementation for CFD review of monitoring dashboard


git filter-branch --force --index-filter "git rm -r --cached --ignore-unmatch venv" --prune-empty --tag-name-filter cat -- --all


tms_token_manager/
â”‚
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ helpers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audit_helper.py       # if applicable
â”‚   â”‚   â”œâ”€â”€ kinesis_helper.py     # if applicable
â”‚   â”‚   â”œâ”€â”€ utils.py              # shared functions or secrets logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ lambda_handler.py         # entry Lambda file
â”‚
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ helpers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ utils.py              # mock/test utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ lambda_handler.py         # for testing only (unit test or mocks)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ template.yaml
â”œâ”€â”€ env-vars.json
â”œâ”€â”€ response.json
â””â”€â”€ README.md

Custom metrics implementation for TT events
CloudWatch Metrics Implementation Requirements
	â€¢	Five custom metrics needed across two Lambda functions:
	â—¦	TT Producer Lambda: S3 records received count, TT events published successfully, TT events failed to publish
	â—¦	Case Creation Lambda: SF case creation success, SF case creation failure
	â€¢	Must implement from code itself, not console
	â—¦	Console-created metrics wonâ€™t show actual data flow
	â—¦	Custom CloudWatch metrics provide real-time success/failure tracking
Current Metrics Issues
	â€¢	Existing AWS metrics insufficient for monitoring:
	â—¦	â€œNumber of objectsâ€ shows file count, not record count within files
	â—¦	â€œInvocationsâ€ shows Lambda execution count, not individual event processing
	â—¦	Example: 1 file with 100 records = 1 invocation but 100 events to track
	â€¢	Need code-level metrics to capture granular success/failure data
Implementation Process
	â€¢	Code changes required in both Lambda functions:
	â—¦	Pull latest code from SAIâ€™s recent structural changes
	â—¦	Create separate branch from base setup to avoid overriding working code
	â—¦	Implement custom CloudWatch metrics within Lambda code
	â€¢	Deployment considerations:
	â—¦	Keep backup of current zip files
	â—¦	Update product template YAML if zip names change
	â—¦	Stack wonâ€™t update, only underlying code changes
Verification & Testing
	â€¢	Metrics automatically appear in CloudWatch after code deployment
	â€¢	Check â€œAll Metricsâ€ â†’ â€œpkyc/Salesforceâ€ namespace for custom metrics
	â€¢	Successful implementation shows graph representation with peaks/valleys
	â€¢	Test with file upload: 5 records should generate 5 case creation success metrics
Next Steps
	â€¢	Pull latest code and create new branch
	â€¢	Implement custom metrics in both Lambda functions
	â€¢	Deploy changes and verify metrics appear in CloudWatch dashboard
	â€¢	Test with sample file upload to confirm tracking accuracy

