Producer lambda changes for parallelization
Shard Distribution Issue
	•	All events going to single shard (Shard 16) despite multiple shards available (7, 11, 14, 16, 17)
	•	Parallelization not taking effect due to poor distribution
	•	Root cause: partition key implementation in producer lambda needs modification
Required Code Changes
	•	Update partition key in BDP Consumer Lambda (rename from “BDP Producer”)
	◦	Change to: existing string + transaction ID
	◦	Generates new partition key for each transaction
	•	Convert remaining printf statements to logger statements
	◦	Code review needed but will be handled separately by Ria
	•	Focus only on partition key changes for now
Deployment Process
	•	Make changes in feature branch without merging initially
	•	Package and deploy lambda to sandbox environment first
	•	Test functionality before proceeding with merge
	•	After deployment confirmed working:
	1	Take pull from base setup branch
	2	Resolve any merge conflicts carefully
	3	Raise PR/MR request
Technical Issues
	•	Screen glitching problems affecting both participants
	◦	Similar issue experienced for 6-7 days previously
	◦	Suspected hardware/heat issues with Mac machines
	•	Display problems may impact development timeline
Next Steps
	•	Immediate: Make partition key changes and deploy to sandbox
	•	Priority: Enable 50,000 record processing capability
	•	Later: Complete branch merging and conflict resolution after initial deployment confirmed working




#
Metric Name
What It Tracks
Where It’s Published (Lambda)
Purpose
1
S3 Record Count
Number of files/records successfully read from the S3 bucket (bbkyc-tc-bdp-bucket or similar)
Lambda: bbkyc-tc-event-producer (after reading from S3)
Helps verify that input data ingestion is working and how many records are processed per trigger.
2
TT Event Publish Success
Count of successful “TT events” pushed into Kinesis Data Stream (bbkyc-tt-event-stream)
Lambda: bbkyc-tt-event-producer
Confirms that event generation and publishing to the stream are functioning as expected.
3
TT Event Publish Failure
Count of failures when publishing TT events to Kinesis
Same Lambda: bbkyc-tt-event-producer (inside catch/error block)
Helps identify reliability issues or connectivity errors with the event stream.
4
Salesforce Case Creation Success
Number of successfully created Salesforce cases (via REST API call)
Lambda: bbkyc-tf-case-creator
Tracks successful case creation in Salesforce — validates downstream integration.
5
Salesforce Case Creation Failure
Number of failed Salesforce case creations
Lambda: bbkyc-tf-case-creator (error handling block)
Detects external API errors, token issues, or invalid data causing failures.



Monitoring dashboard setup for AWS Lambda metrics
AWS CloudWatch Dashboard Setup
	•	Lambda trigger process explanation
	◦	Upload JSON file to S3 → Lambda triggers → Metrics generated → Pushed to internal metric store
	◦	Monitoring dashboard reads metric points independently of alarm triggers
	◦	Statistical analysis options: average, summation, P99 percentile calculations
	•	Widget configuration walkthrough
	◦	Add multiple metrics to same widget via plus button → Browse → AWS Lambda namespace
	◦	Search by function name or resource name
	◦	Graph matrices tab shows multiple values
	◦	Rename widget labels for clarity (AWS generates random unique names)
Error Handling Strategy
	•	Two approaches for Lambda error tracking
	1	Code fails → Lambda fails → Error propagates to top (captured by AWS Lambda error matrix)
	2	Handle errors in code → Lambda never fails → Generate custom error matrices from code
	•	Review existing producer Lambda error handling
	◦	Determine if failures are captured at Lambda error matrix level
	◦	Decide between infrastructure-level vs application-level error tracking
	•	Widget naming: Use descriptive titles like “TT Publish failure” instead of AWS defaults
Dashboard Enhancement Requirements
	•	Add text sections describing what matrices mean
	◦	Business users need context without technical knowledge
	◦	Make dashboard self-explanatory for non-developers
	•	Uncheck sparkline option to reduce visual clutter (Edit → Options tab)
	•	Current data shows only single record processing - need more data for proper testing
Next Steps
	•	Ria: Resolve WiFi issues, complete scenario generation
	•	Review and update error handling in producer Lambda
	•	Beautify dashboard with descriptive text sections
	•	Follow up after implementation for CFD review of monitoring dashboard


git filter-branch --force --index-filter "git rm -r --cached --ignore-unmatch venv" --prune-empty --tag-name-filter cat -- --all


tms_token_manager/
│
├── main/
│   ├── helpers/
│   │   ├── __init__.py
│   │   ├── audit_helper.py       # if applicable
│   │   ├── kinesis_helper.py     # if applicable
│   │   ├── utils.py              # shared functions or secrets logic
│   ├── __init__.py
│   └── lambda_handler.py         # entry Lambda file
│
├── test/
│   ├── helpers/
│   │   ├── __init__.py
│   │   ├── utils.py              # mock/test utilities
│   ├── __init__.py
│   └── lambda_handler.py         # for testing only (unit test or mocks)
│
├── requirements.txt
├── template.yaml
├── env-vars.json
├── response.json
└── README.md

Custom metrics implementation for TT events
CloudWatch Metrics Implementation Requirements
	•	Five custom metrics needed across two Lambda functions:
	◦	TT Producer Lambda: S3 records received count, TT events published successfully, TT events failed to publish
	◦	Case Creation Lambda: SF case creation success, SF case creation failure
	•	Must implement from code itself, not console
	◦	Console-created metrics won’t show actual data flow
	◦	Custom CloudWatch metrics provide real-time success/failure tracking
Current Metrics Issues
	•	Existing AWS metrics insufficient for monitoring:
	◦	“Number of objects” shows file count, not record count within files
	◦	“Invocations” shows Lambda execution count, not individual event processing
	◦	Example: 1 file with 100 records = 1 invocation but 100 events to track
	•	Need code-level metrics to capture granular success/failure data
Implementation Process
	•	Code changes required in both Lambda functions:
	◦	Pull latest code from SAI’s recent structural changes
	◦	Create separate branch from base setup to avoid overriding working code
	◦	Implement custom CloudWatch metrics within Lambda code
	•	Deployment considerations:
	◦	Keep backup of current zip files
	◦	Update product template YAML if zip names change
	◦	Stack won’t update, only underlying code changes
Verification & Testing
	•	Metrics automatically appear in CloudWatch after code deployment
	•	Check “All Metrics” → “pkyc/Salesforce” namespace for custom metrics
	•	Successful implementation shows graph representation with peaks/valleys
	•	Test with file upload: 5 records should generate 5 case creation success metrics
Next Steps
	•	Pull latest code and create new branch
	•	Implement custom metrics in both Lambda functions
	•	Deploy changes and verify metrics appear in CloudWatch dashboard
	•	Test with sample file upload to confirm tracking accuracy

