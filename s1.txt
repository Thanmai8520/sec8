npm config set proxy http://primary-proxy.gslb.intranet.barcapint.com:8080
npm config set https-proxy http://primary-proxy.gslb.intranet.barcapint.com:8080
npm config set strict-ssl false


npm config list
curl -I https://registry.npmjs.org

sudo xcode-select -s /Applications/Xcode.app/Contents/Developer
sudo xcodebuild -license
xcode-select --install
xcode-select -p


export DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer
export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES

echo 'export DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer' >> ~/.zshrc
echo 'export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES' >> ~/.zshrc
source ~/.zshrc


Hi Sumanta,
I was referred to you by Sai Krishna regarding creating a DevOps strategy for our Lambda functions to flow from GitLab to AWS. I’d like to discuss the current approach and understand what’s going on with it. Please let me know a convenient time to connect.


Just to clarify our flow — after the code is committed to GitLab, do we have a CI/CD pipeline that publishes artifacts to Nexus? And from Nexus, is there another pipeline that uploads them to S3 for Lambda deployments?


import boto3
import base64
import json
import os
from datetime import datetime

# Kinesis client
kinesis = boto3.client("kinesis")

# Destination stream from environment variable
CTA_EVENT_STREAM = os.environ["CTA_EVENT_STREAM"]

def lambda_handler(event, context):
    records_to_put = []

    for record in event["Records"]:
        # Decode the incoming TT event
        payload = base64.b64decode(record["kinesis"]["data"]).decode("utf-8")
        event_data = json.loads(payload)

        # --- Apply CTA Rule Processing (example rule) ---
        cta_event = {
            "ttEventId": event_data.get("id"),
            "status": "CTA_READY" if event_data.get("priority") == "HIGH" else "CTA_PENDING",
            "timestamp": datetime.utcnow().isoformat(),
            "originalEvent": event_data
        }

        # Prepare record for CTA event stream
        records_to_put.append({
            "Data": json.dumps(cta_event).encode("utf-8"),
            "PartitionKey": record["kinesis"]["partitionKey"]
        })

    # Push batch to CTA event stream
    if records_to_put:
        response = kinesis.put_records(
            StreamName=CTA_EVENT_STREAM,
            Records=records_to_put
        )
        print("PutRecords response:", response)

    return {
        "statusCode": 200,
        "body": f"Processed {len(records_to_put)} TT events into CTA events"
    }