Dashboard should have: tally up the info how many publish as an event, how many cases sucess for tt events, failure for reason, 
1. S3 how many
2. Sales forces cases how many -failed and pass metrics


aws lambda update-function-code \
--function-name bbkyc-tms-token-manager-dev-lambda \
--s3-bucket bbkyc-lambda-code-dev-bucket \
--s3-key bbkyc-tms-token-manager-lambda-new.zip \
--region eu-west-2

aws lambda invoke \
--function-name bbkyc-tms-token-manager-dev-lambda \
--payload '{}' \
--region eu-west-2 \
response.json

cat response.json
PKYC-INFRA/
│
├── app-iam-roles/
│   ├── metadata.yaml
│   ├── product.template.yaml
│   └── README.md
│
├── dynamo-dbs/
│   └── product.template.yaml
│
├── kinesis-streams/
│   └── product.template.yaml
│
├── s3-buckets/
│   ├── op/
│   │   └── metadata.yaml
│   └── tm/
│       └── product.template.yaml
│
├── G015/
│   ├── README.md
│   └── tms-token-manager-lambda/
│       ├── iam-roles.yaml
│       ├── README.md
│       └── modules/
│
└── TracFi/



PROJECT1
│
├── bb-pkyc-ttbdpprocessor
│   ├── .venv
│   ├── bdp-consumer-lambda
│   ├── case-creation-lambda
│   ├── cft
│   │   ├── app-iam-roles
│   │   ├── dynamo-dbs
│   │   ├── kinesis-streams
│   │   ├── lambdas
│   │   ├── s3-buckets
│   │   ├── sqs
│   │   ├── iam-roles.yaml
│   │   └── sample-cft.yaml
│   │
│   ├── cta-rules-lambda
│   ├── shared
│   ├── .gitignore
│   ├── bbkyc-cta-rule-lambda.zip
│   ├── metadata.yaml
│   ├── product.template.yaml
│   ├── README.md
│   └── setup.sh

AWS Lambda: bbkyc-tms-token-manager

🔹 Purpose

Manages the TMS token lifecycle —
fetches, validates, and updates the token used by downstream services (like bbkyc-sf-case-creator).

⸻

🔹 Trigger
	•	Source: AWS EventBridge
	•	Rule Name: bbkyc-tms-scheduler
	•	Schedule: Every 55 minutes
	•	Active Window: Between 12 AM and 3 AM (processor days)

⸻

🔹 Execution Flow

1️⃣ Trigger

AWS EventBridge invokes the Lambda (bbkyc-tms-token-manager) every 55 minutes.

2️⃣ Token Fetch & Validation
	•	The Lambda fetches the current TMS token from:
	•	AWS Secrets Manager
	•	Secret Name: bbkyc-tms-token

3️⃣ Validate Token
	•	Calls Border Control API endpoint (external REST API)
	•	Purpose: Check if the stored TMS token is still valid.
	•	API Example: https://bordercontrol.example.com/validate
	•	If token is valid → end process (no change).
	•	If token is invalid / expired → immediately fetch a new token.

4️⃣ Fetch New Token
	•	Calls another Border Control API endpoint:
	•	API Example: https://bordercontrol.example.com/token
	•	Uses credentials or payload (e.g., username/password or API key)
	•	Receives a new TMS token in API response.

5️⃣ Update Token in Secrets Manager
	•	Overwrites the old secret with new JSON:





npm config set proxy http://primary-proxy.gslb.intranet.barcapint.com:8080
npm config set https-proxy http://primary-proxy.gslb.intranet.barcapint.com:8080
npm config set strict-ssl false


npm config list
curl -I https://registry.npmjs.org

sudo xcode-select -s /Applications/Xcode.app/Contents/Developer
sudo xcodebuild -license
xcode-select --install
xcode-select -p


export DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer
export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES

echo 'export DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer' >> ~/.zshrc
echo 'export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES' >> ~/.zshrc
source ~/.zshrc


Hi Sumanta,
I was referred to you by Sai Krishna regarding creating a DevOps strategy for our Lambda functions to flow from GitLab to AWS. I’d like to discuss the current approach and understand what’s going on with it. Please let me know a convenient time to connect.


Just to clarify our flow — after the code is committed to GitLab, do we have a CI/CD pipeline that publishes artifacts to Nexus? And from Nexus, is there another pipeline that uploads them to S3 for Lambda deployments?


import boto3
import base64
import json
import os
from datetime import datetime

# Kinesis client
kinesis = boto3.client("kinesis")

# Destination stream from environment variable
CTA_EVENT_STREAM = os.environ["CTA_EVENT_STREAM"]

def lambda_handler(event, context):
    records_to_put = []

    for record in event["Records"]:
        # Decode the incoming TT event
        payload = base64.b64decode(record["kinesis"]["data"]).decode("utf-8")
        event_data = json.loads(payload)

        # --- Apply CTA Rule Processing (example rule) ---
        cta_event = {
            "ttEventId": event_data.get("id"),
            "status": "CTA_READY" if event_data.get("priority") == "HIGH" else "CTA_PENDING",
            "timestamp": datetime.utcnow().isoformat(),
            "originalEvent": event_data
        }

        # Prepare record for CTA event stream
        records_to_put.append({
            "Data": json.dumps(cta_event).encode("utf-8"),
            "PartitionKey": record["kinesis"]["partitionKey"]
        })

    # Push batch to CTA event stream
    if records_to_put:
        response = kinesis.put_records(
            StreamName=CTA_EVENT_STREAM,
            Records=records_to_put
        )
        print("PutRecords response:", response)

    return {
        "statusCode": 200,
        "body": f"Processed {len(records_to_put)} TT events into CTA events"
    }